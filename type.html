<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>AI Project</title>
    <style>
    *{
            margin: 0;
        }
        h1{
            background-color:black;
            color:white;
            text-align:center;
            padding:10px;
            font-style:oblique;
        }
       nav ul{
            background-color:darkgoldenrod;
            text-align: center;
            padding:10px;
        }
       nav ul li{
            list-style-type: none;
            display:inline-block;
            margin:5px;
           padding: 10px;
            font-style:oblique;
           font-size:large;
        }
        nav ul li a{
            text-decoration: none;
            color:yellow;
        }
         nav ul li:hover{
                background-color:black;
                border-radius:5px;
            }
        .active,.new,.less{
            line-height:27px
        }
        h3{
            color:white;
            background-color: black;
            font-style:oblique;
            width:224px;height:35px;border-radius:3px;
                text-align: center;
        }
    
         section{
           margin:10px;
            font-style: oblique;
            font-size:large
        }
        table{
            position:relative;
            left:485px;top:16px
        }
        hr{
            border:1px outset #EEE;
            width:700px;
        }
    
    </style>
</head>
    
<body>
    
   <h1>Types of AI</h1><hr>
    <nav>
    <ul>
        <li><a href="breif.html">brief summary about AI</a></li>
        <li><a href="type.html">Types of AI</a></li>
        <li><a href="use.html">The benefits of AI</a></li>
        <li><a href="statistics.html">Statistics about AI around the whole world</a></li>
        <li><a href="create.html">The Creators of AI throughout the ages</a></li>
        </ul>
    </nav> 
    <table border="1" width="600"height="500" style="text-align: center">
     <tr>
         <th>Types of AI</th>
        </tr>
        <tr>
            <td>REACTIVE MACHINES</td>
        </tr>
        <tr>
         <td>LIMITED MEMORY</td>
        </tr>
    <tr>
         <td>THEORY OF MIND</td>
        </tr>
        <tr>
         <td>SELF-AWARENESS</td>
        </tr>
    </table>
    
    
    
    <section>
    <h3 class="at">REACTIVE MACHINES</h3><br>
        <p>The most basic types of AI systems are purely reactive, and have the ability<br> neither to form memories nor to use past experiences to inform current<br> decisions. Deep Blue, IBM’s chess-playing supercomputer, which beat<br> international grandmaster Garry Kasparov in the late 1990s, is the perfect<br> example of this type of machine.<br><br>Deep Blue can identify the pieces on a chess board and know how each moves. It<br> can make predictions about what moves might be next for it and its opponent.<br> And it can choose the most optimal moves from among the possibilities.<br><br>But it doesn’t have any concept of the past, nor any memory of what has<br> happened before. Apart from a rarely used chess-specific rule against repeating<br> the same move three times, Deep Blue ignores everything before the present<br> moment. All it does is look at the pieces on the chess board as it stands right<br> now, and choose from possible next moves.<br><br>This type of intelligence involves the computer perceiving the world directly and<br> acting on what it sees. It doesn’t rely on an internal concept of the world. In a<br> seminal paper, AI researcher Rodney Brooks argued that we should only build<br> machines like this. His main reason was that people are not very good at<br> programming accurate simulated worlds for computers to use, what is called in<br> AI scholarship a “representation” of the world.
        </p><br><hr><br>
    <h3>LIMITED MEMORY</h3><br>
        <p class="less">This Type II class contains machines can look into the past. Self-driving cars do<br> some of this already. For example, they observe other cars’ speed and direction.<br> That can’t be done in a just one moment, but rather requires identifying specific<br> objects and monitoring them over time.<br><br>These observations are added to the self-driving cars’ preprogrammed<br> representations of the world, which also include lane markings, traffic lights and<br> other important elements, like curves in the road. They’re included when the car<br> decides when to change lanes, to avoid cutting off another driver or being hit by<br> a nearby car.<br><br>But these simple pieces of information about the past are only transient. They<br> aren’t saved as part of the car’s library of experience it can learn from, the way<br> human drivers compile experience over years behind the wheel.<br><br>So how can we build AI systems that build full representations, remember their<br> experiences and learn how to handle new situations? Brooks was right in that it<br> is very difficult to do this. My own research into methods inspired by Darwinian<br> evolution can start to make up for human shortcomings by letting the machines<br> build their own representations.
        </p><br><hr><br>
    <h3>THEORY OF MIND</h3><br>
        <p class="new">
         We might stop here, and call this point the important divide between the<br> machines we have and the machines we will build in the future. However, it is<br> better to be more specific to discuss the types of representations machines need<br> to form, and what they need to be about.<br><br>

        Machines in the next, more advanced, class not only form representations about<br> the world, but also about other agents or entities in the world. In psychology,<br> this is called “theory of mind” – the understanding that people, creatures and<br> objects in the world can have thoughts and emotions that affect their own<br> behavior.<br><br>

        This is crucial to how we humans formed societies, because they allowed us to<br> have social interactions. Without understanding each other’s motives and<br> intentions, and without taking into account what somebody else knows either<br> about me or the environment, working together is at best difficult, at worst<br> impossible.<br><br>

        If AI systems are indeed ever to walk among us, they’ll have to be able to<br> understand that each of us has thoughts and feelings and expectations for how<br> we’ll be treated. And they’ll have to adjust their behavior accordingly.</p><br><hr><br>
    <h3>SELF-AWARENESS</h3><br>
        <p class="active">
      The final step of AI development is to build systems that can form<br> representations about themselves. Ultimately, we AI researchers will have to not<br> only understand consciousness, but build machines that have it.<br><br>

      This is, in a sense, an extension of the “theory of mind” possessed by Type III<br> artificial intelligences. Consciousness is also called “self-awareness” for a reason.<br> (“I want that item” is a very different statement from “I know I want that item.”)<br> Conscious beings are aware of themselves, know about their internal states, and<br> are able to predict feelings of others. We assume someone honking behind us in<br> traffic is angry or impatient, because that’s how we feel when we honk at others.<br> Without a theory of mind, we could not make those sorts of inferences.<br><br>

      While we are probably far from creating machines that are self-aware, we should<br> focus our efforts toward understanding memory, learning and the ability to base<br> decisions on past experiences. This is an important step to understand human<br> intelligence on its own. And it is crucial if we want to design or evolve machines<br> that are more than exceptional at classifying what they see in front of them. </p><br>

    
    </section>
    
    
    
    
    
    
    
</body>

</html>